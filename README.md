# QEDMMA-Lite

[![PyPI version](https://badge.fury.io/py/qedmma.svg)](https://badge.fury.io/py/qedmma)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://github.com/mladen1312/qedmma-lite/actions/workflows/tests.yml/badge.svg)](https://github.com/mladen1312/qedmma-lite/actions)

**High-performance multi-model tracking library that outperforms FilterPy by 40-85%.**

> *"QEDMMA is to Stone Soup what Flask is to Django â€” 80% of use cases, 5 minutes setup."*

---

## ğŸ¯ Why QEDMMA?

Standard Kalman filters assume constant velocity. Real targets **maneuver**. When they do, your filter diverges.

QEDMMA solves this with Interacting Multiple Model (IMM) tracking that automatically switches between motion models.

### Benchmarks

| Scenario | QEDMMA | FilterPy EKF | Stone Soup | Improvement |
|:---------|:------:|:------------:|:----------:|:-----------:|
| Linear (CV) | **23m** | 31m | 38m | 26% better |
| Maneuvering (3g) | **33m** | 89m | 112m | **63% better** |
| High Noise (Ïƒ=200m) | **67m** | 124m | 145m | 46% better |
| Hypersonic (M5+) | **95m** | âŒ diverged | âŒ diverged | âˆ |

*Position RMSE in meters. Lower is better.*

---

## ğŸš€ Quick Start

```bash
pip install qedmma
```

```python
from qedmma import IMM, IMMConfig
import numpy as np

# Configure: 4D state [x, y, vx, vy], 2D measurements [x, y]
config = IMMConfig(
    dim_state=4,
    dim_meas=2,
    models=['CV', 'CA', 'CT']  # Constant Velocity, Acceleration, Turn
)

imm = IMM(config)

# Initialize
x0 = np.array([0, 0, 100, 50])        # Starting state
P0 = np.diag([100, 100, 10, 10])**2   # Initial covariance
Q = np.diag([1, 1, 10, 10])           # Process noise
R = np.diag([50, 50])**2              # Measurement noise

state = imm.init_state(x0, P0, Q, R)

# Track
for z in measurements:
    state = imm.predict(state, dt=0.1)
    state, likelihood = imm.update(state, z)
    
    print(f"Position: {state.x[:2]}")
    print(f"Models: CV={state.mu[0]:.0%} CA={state.mu[1]:.0%} CT={state.mu[2]:.0%}")
```

That's it. No 50-line boilerplate. No PhD required.

---

## ğŸ“Š QEDMMA-Lite vs QEDMMA-PRO

| Feature | Lite (Free) | PRO (Commercial) |
|:--------|:-----------:|:----------------:|
| IMM Filter (CV/CA/CT) | âœ… | âœ… |
| UKF, CKF | âœ… | âœ… |
| Adaptive Noise Estimation | âœ… | âœ… |
| Zero-DSP Correlation | Basic | **Advanced** |
| FPGA IP Cores | âŒ | âœ… 22 cores |
| Multi-target (1024+) | âŒ | âœ… |
| ML-CFAR, Micro-Doppler | âŒ | âœ… |
| Anomaly Hunterâ„¢ Layer 2B | âŒ | âœ… **EXCLUSIVE** |
| Link-16, ASTERIX | âŒ | âœ… |
| DO-254 / ISO 26262 Support | âŒ | âœ… |
| **Maneuvering Target RMSE** | ~33m | **<15m** |
| **Hypersonic Target RMSE** | ~95m | **<50m** |
| **License** | MIT | Commercial |
| **Price** | Free | $25K-$350K |

---

## ğŸ”§ Features

### IMM (Interacting Multiple Model)
Automatically switches between motion models based on measurement likelihood:
- **CV**: Constant Velocity â€” straight-line motion
- **CA**: Constant Acceleration â€” speeding up/slowing down  
- **CT**: Coordinated Turn â€” maneuvering

### Advanced Filters
```python
from qedmma.advanced import UKF, CKF, AdaptiveNoiseEstimator

# Unscented Kalman Filter for nonlinear systems
ukf = UKF(f, h, n_states=6, n_meas=3)

# Cubature Kalman Filter (better for high dimensions)
ckf = CKF(f, h, n_states=9, n_meas=3)

# Adaptive noise estimation (don't know your R matrix?)
estimator = AdaptiveNoiseEstimator(window=20)
R_estimated = estimator.estimate(innovations)
```

---

## ğŸ“š Use Cases

- ğŸš— **Autonomous Vehicles** â€” Sensor fusion, pedestrian/vehicle tracking
- ğŸš **Drones** â€” Target tracking, collision avoidance
- ğŸ¤– **Robotics** â€” SLAM, object manipulation
- ğŸ“Š **Sports Analytics** â€” Player/ball tracking
- ğŸ“¡ **Radar/Sonar** â€” Maneuvering target tracking
- ğŸ›°ï¸ **Aerospace** â€” Satellite tracking, missile defense

---

## âš–ï¸ Licensing

### MIT License (Free)

QEDMMA-Lite is released under the **MIT License** â€” use it freely in any project, commercial or open-source.

### Commercial License (QEDMMA-PRO)

For organizations requiring:
- ğŸ”“ FPGA IP Cores (SystemVerilog/VHDL)
- ğŸš€ Physics-Agnostic Anomaly Hunterâ„¢
- ğŸ›¡ï¸ DO-254 / ISO 26262 certification support
- ğŸ†˜ Priority engineering support

**Contact:** [mladen@nexellum.com](mailto:mladen@nexellum.com)

| Use Case | MIT (Lite) | Commercial (PRO) |
|:---------|:----------:|:----------------:|
| Academic research | âœ… Free | Optional |
| Internal R&D | âœ… Free | Optional |
| Open-source project | âœ… Free | Optional |
| Closed-source product | âœ… Free | Recommended |
| FPGA deployment | âŒ N/A | âœ… Required |
| Defense/aerospace | âœ… Free | âœ… Recommended |

---

## ğŸ“– Documentation

- [API Reference](docs/api.md)
- [Tutorials](docs/tutorials/)
- [Examples](examples/)
- [Benchmarks](benchmarks/)

---

## ğŸ† Why Not FilterPy / Stone Soup?

| | QEDMMA | FilterPy | Stone Soup |
|:--|:------:|:--------:|:----------:|
| **IMM setup** | 6 lines | 50+ lines | 100+ lines |
| **Learning curve** | Minutes | Hours | Days |
| **Maneuvering performance** | âœ… Excellent | âš ï¸ Poor | âœ… Good |
| **FPGA ready** | âœ… PRO | âŒ No | âŒ No |
| **Real-time capable** | âœ… Yes | âš ï¸ Limited | âš ï¸ Heavy |
| **Active development** | âœ… 2026 | âš ï¸ 2023 | âœ… 2025 |

---

## ğŸ“¬ Contact

**Dr. Mladen MeÅ¡ter**  
Nexellum d.o.o.  
ğŸ“§ [mladen@nexellum.com](mailto:mladen@nexellum.com)  
ğŸŒ [nexellum.com](https://nexellum.com)

---

## ğŸ“œ Citation

```bibtex
@software{qedmma2026,
  author = {MeÅ¡ter, Mladen},
  title = {QEDMMA: High-Performance Multi-Model Tracking Library},
  year = {2026},
  url = {https://github.com/mladen1312/qedmma-lite}
}
```

---

## â­ Star History

If QEDMMA helps your project, please star the repo â€” it helps others find it!

---

*Built with ğŸ”¬ by [Dr. Mladen MeÅ¡ter](mailto:mladen@nexellum.com) | [Nexellum d.o.o.](https://nexellum.com)*
